# ü§ñCS RAG Chatbot

‡∏£‡∏∞‡∏ö‡∏ö RAG (Retrieval-Augmented Generation) Chatbot ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ ‡πÉ‡∏ä‡πâ Local LLM ‡πÅ‡∏•‡∏∞ Embedding Models

### 1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama

#### Windows
```bash
# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å https://ollama.ai
# ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ winget
winget install ollama
```

#### macOS
```bash
# ‡πÉ‡∏ä‡πâ Homebrew
brew install ollama

# ‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å https://ollama.ai
```

#### Linux
```bash
curl https://ollama.ai/install.sh | sh
```

### 2. ‡∏£‡∏±‡∏ô Ollama ‡πÅ‡∏•‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•

#### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Windows (‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á ollama ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô)
```bash
# ‡πÉ‡∏ä‡πâ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ
setup_ollama.bat

# ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏ï‡πá‡∏°
& "C:\Users\$env:USERNAME\AppData\Local\Programs\Ollama\ollama.exe" serve
```

#### ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏õ‡∏Å‡∏ï‡∏¥ (‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏° PATH ‡πÅ‡∏•‡πâ‡∏ß)
```bash
# ‡πÄ‡∏£‡∏¥‡πà‡∏° Ollama server
ollama serve

# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• LLM (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 1 ‡∏≠‡∏±‡∏ô)
ollama pull llama3.1:8b      # ‡πÄ‡∏£‡πá‡∏ß, RAM ‡∏ô‡πâ‡∏≠‡∏¢ (8GB)
ollama pull gemma2:2b        # ‡πÄ‡∏•‡πá‡∏Å‡∏°‡∏≤‡∏Å, RAM ‡∏ô‡πâ‡∏≠‡∏¢ (2GB)
ollama pull llama3.1:70b     # ‡∏™‡∏°‡∏î‡∏∏‡∏• (80GB)
ollama pull codellama:7b     # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡πâ‡∏î (7GB)
```

### 3. Clone ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå

```bash
git clone <repository-url>
cd thai-rag-chatbot
```

### 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á Virtual Environment

#### Windows
```bash
python -m venv venv
venv\Scripts\activate
```

#### macOS/Linux
```bash
python3 -m venv venv
source venv/bin/activate
```

### 5. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies

```bash
pip install -r requirements.txt
```

### 6. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Environment (‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö)

```bash
# ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
copy .env.example .env

# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
notepad .env  # Windows
nano .env     # macOS/Linux
```

## üéØ ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

1. **‡πÄ‡∏õ‡∏¥‡∏î Ollama Server**
   ```bash
   ollama serve
   ```

2. **‡∏£‡∏±‡∏ô‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô**
   ```bash
   streamlit run app.py
   ```

3. **‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå** ‡πÑ‡∏õ‡∏ó‡∏µ‡πà `http://localhost:8501`

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

1. **‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö**
   - ‡πÑ‡∏õ‡∏ó‡∏µ‡πà Sidebar ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• Embedding ‡πÅ‡∏•‡∏∞ LLM
   - ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° "‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö"

2. **‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£**
   - ‡πÑ‡∏õ‡πÅ‡∏ó‡πá‡∏ö "‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"
   - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå PDF, DOCX, TXT ‡∏´‡∏£‡∏∑‡∏≠ PPTX
   - ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° "‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"

3. **‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏ô‡∏ó‡∏ô‡∏≤**
   - ‡πÑ‡∏õ‡πÅ‡∏ó‡πá‡∏ö "‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"
   - ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î
   - ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ï‡∏≠‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

## üìÅ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå

```
thai-rag-chatbot/
‚îú‚îÄ‚îÄ app.py                 # ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö Streamlit ‡∏´‡∏•‡∏±‡∏Å
‚îú‚îÄ‚îÄ requirements.txt       # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ dependencies
‚îú‚îÄ‚îÄ .env.example          # ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
‚îú‚îÄ‚îÄ README.md             # ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ô‡∏µ‡πâ
‚îÇ
‚îú‚îÄ‚îÄ src/                  # ‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ document_processor.py    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
‚îÇ   ‚îú‚îÄ‚îÄ vector_store.py         # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Vector Store
‚îÇ   ‚îî‚îÄ‚îÄ rag_system.py          # ‡∏£‡∏∞‡∏ö‡∏ö RAG
‚îÇ
‚îú‚îÄ‚îÄ config/              # ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ config.py       # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ configuration
‚îÇ
‚îú‚îÄ‚îÄ data/               # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
‚îú‚îÄ‚îÄ vectorstore/        # ‡πÄ‡∏Å‡πá‡∏ö Vector Database
‚îî‚îÄ‚îÄ temp/              # ‡πÑ‡∏ü‡∏•‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
```

## ‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•

### Embedding Models (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)

| ‡πÇ‡∏°‡πÄ‡∏î‡∏• | ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß | ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û | RAM | ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö |
|-------|----------|--------|-----|-------------|
| `paraphrase-multilingual-MiniLM-L12-v2` | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | 1GB | ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ, ‡πÄ‡∏£‡πá‡∏ß |
| `distiluse-base-multilingual-cased` | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | 2GB | ‡∏™‡∏°‡∏î‡∏∏‡∏• |
| `paraphrase-multilingual-mpnet-base-v2` | ‚≠ê | ‚≠ê‚≠ê‚≠ê | 4GB | ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á |

### LLM Models (Ollama)

| ‡πÇ‡∏°‡πÄ‡∏î‡∏• | ‡∏Ç‡∏ô‡∏≤‡∏î | RAM ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ | ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö |
|-------|------|-------------|-------------|
| `gemma2:2b` | 2B | 4GB | **‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô** ‚≠ê |
| `llama3.1:8b` | 8B | 8GB | ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ, ‡πÄ‡∏£‡πá‡∏ß |
| `llama3.1:70b` | 70B | 80GB | ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á |
| `codellama:7b` | 7B | 7GB | ‡πÇ‡∏Ñ‡πâ‡∏î, ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ |
| `mistral:7b` | 7B | 7GB | ‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ |

## üîß ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢

#### 1. ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á ollama ‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (Windows)
```bash
# ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: ollama is not recognized
# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç 1: ‡πÉ‡∏ä‡πâ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ
setup_ollama.bat

# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç 2: ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏ï‡πá‡∏°
& "C:\Users\$env:USERNAME\AppData\Local\Programs\Ollama\ollama.exe" --version

# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç 3: ‡πÄ‡∏û‡∏¥‡πà‡∏° PATH ‡∏ñ‡∏≤‡∏ß‡∏£ (‡πÄ‡∏õ‡∏¥‡∏î Command Prompt as Administrator)
setx PATH "%PATH%;C:\Users\%USERNAME%\AppData\Local\Programs\Ollama"
```

#### 2. Ollama ‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠
```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Ollama ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
ollama list

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö port
netstat -ano | findstr :11434

# ‡∏£‡∏µ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó Ollama
# Windows: ‡∏£‡∏µ‡∏™‡∏ï‡∏≤‡∏£‡πå‡∏ó‡∏à‡∏≤‡∏Å Services ‡∏´‡∏£‡∏∑‡∏≠ Task Manager
# macOS/Linux: 
killall ollama
ollama serve
```

#### 2. ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
```bash
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏•
ollama list

# ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà
ollama pull llama3.1:8b
```

#### 3. Memory Error
- ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤
- ‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏≠‡∏∑‡πà‡∏ô‡πÜ
- ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î chunk_size ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤

#### 4. ‡πÑ‡∏ü‡∏•‡πå‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö encoding ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå
- ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå UTF-8
- ‡∏•‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô PDF

### ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

#### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ RAM ‡∏ô‡πâ‡∏≠‡∏¢
```python
# ‡πÉ‡∏ô config/config.py ‡∏´‡∏£‡∏∑‡∏≠ .env
DEFAULT_CHUNK_SIZE=500
DEFAULT_CHUNK_OVERLAP=100
BATCH_SIZE=16
```

#### ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ RAM ‡πÄ‡∏¢‡∏≠‡∏∞
```python
DEFAULT_CHUNK_SIZE=1500
DEFAULT_CHUNK_OVERLAP=300
BATCH_SIZE=64
```






