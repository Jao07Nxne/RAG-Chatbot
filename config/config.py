"""
Configuration Manager for Thai RAG Chatbot
‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö
"""

import os
from typing import Dict, Any, List
from pathlib import Path
from dotenv import load_dotenv

# ‡πÇ‡∏´‡∏•‡∏î environment variables
load_dotenv()


class Config:
    """‡∏Ñ‡∏•‡∏≤‡∏™‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ configuration"""
    
    # =============================================
    # Ollama Configuration
    # =============================================
    OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
    OLLAMA_TIMEOUT = int(os.getenv("OLLAMA_TIMEOUT", "60"))
    
    # =============================================
    # Model Configuration
    # =============================================
    DEFAULT_EMBEDDING_MODEL = os.getenv(
        "DEFAULT_EMBEDDING_MODEL", 
        "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    )
    
    DEFAULT_LLM_MODEL = os.getenv("DEFAULT_LLM_MODEL", "gemma2:2b")
    
    # Model Parameters
    DEFAULT_TEMPERATURE = float(os.getenv("DEFAULT_TEMPERATURE", "0.1"))
    DEFAULT_MAX_TOKENS = int(os.getenv("DEFAULT_MAX_TOKENS", "2048"))
    DEFAULT_CHUNK_SIZE = int(os.getenv("DEFAULT_CHUNK_SIZE", "1000"))
    DEFAULT_CHUNK_OVERLAP = int(os.getenv("DEFAULT_CHUNK_OVERLAP", "200"))
    
    # =============================================
    # File and Storage Configuration
    # =============================================
    VECTOR_STORE_PATH = os.getenv("VECTOR_STORE_PATH", "./vectorstore")
    DATA_DIR = os.getenv("DATA_DIR", "./data")
    TEMP_DIR = os.getenv("TEMP_DIR", "./temp")
    
    # File size limit (50MB)
    MAX_FILE_SIZE = int(os.getenv("MAX_FILE_SIZE", "52428800"))
    
    # Supported file extensions
    SUPPORTED_EXTENSIONS = os.getenv(
        "SUPPORTED_EXTENSIONS", 
        ".txt,.pdf,.docx,.doc,.pptx,.ppt"
    ).split(",")
    
    # =============================================
    # Streamlit Configuration
    # =============================================
    STREAMLIT_PAGE_TITLE = os.getenv("STREAMLIT_PAGE_TITLE", "Thai RAG Chatbot")
    STREAMLIT_PAGE_ICON = os.getenv("STREAMLIT_PAGE_ICON", "ü§ñ")
    STREAMLIT_LAYOUT = os.getenv("STREAMLIT_LAYOUT", "wide")
    MAX_UPLOAD_SIZE = int(os.getenv("MAX_UPLOAD_SIZE", "50"))
    
    # =============================================
    # Thai Language Processing
    # =============================================
    THAI_TOKENIZER = os.getenv("THAI_TOKENIZER", "newmm")
    THAI_ENCODINGS = os.getenv("THAI_ENCODINGS", "utf-8,cp874,iso-8859-11").split(",")
    
    # =============================================
    # Performance Configuration
    # =============================================
    DEFAULT_SEARCH_K = int(os.getenv("DEFAULT_SEARCH_K", "5"))
    SIMILARITY_THRESHOLD = float(os.getenv("SIMILARITY_THRESHOLD", "0.0"))
    MAX_CHAT_HISTORY_LENGTH = int(os.getenv("MAX_CHAT_HISTORY_LENGTH", "50"))
    BATCH_SIZE = int(os.getenv("BATCH_SIZE", "32"))
    
    @classmethod
    def get_embedding_models(cls) -> Dict[str, str]:
        """‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏• embedding ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö"""
        return {
            "fast": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            "balanced": "sentence-transformers/distiluse-base-multilingual-cased",
            "best": "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
            "thai_optimized": "sentence-transformers/LaBSE"
        }
    
    @classmethod
    def get_llm_models(cls) -> Dict[str, str]:
        """‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏°‡πÄ‡∏î‡∏• LLM ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥"""
        return {
            "small_fast": "llama3.1:8b",
            "balanced": "llama3.1:70b", 
            "large": "llama3.1:405b",
            "coding": "codellama:7b",
            "chat": "mistral:7b"
        }
    
    @classmethod
    def create_directories(cls) -> None:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
        dirs_to_create = [
            cls.VECTOR_STORE_PATH,
            cls.DATA_DIR,
            cls.TEMP_DIR
        ]
        
        for dir_path in dirs_to_create:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    @classmethod
    def validate_file(cls, file_path: str, file_size: int) -> tuple[bool, str]:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        file_ext = Path(file_path).suffix.lower()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå
        if file_size > cls.MAX_FILE_SIZE:
            return False, f"‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î {cls.MAX_FILE_SIZE / 1024 / 1024:.1f} MB)"
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå
        if file_ext not in cls.SUPPORTED_EXTENSIONS:
            return False, f"‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó {file_ext}"
        
        return True, "‡πÑ‡∏ü‡∏•‡πå‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á"
    
    @classmethod
    def get_config_summary(cls) -> Dict[str, Any]:
        """‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"""
        return {
            "ollama": {
                "base_url": cls.OLLAMA_BASE_URL,
                "timeout": cls.OLLAMA_TIMEOUT
            },
            "models": {
                "default_embedding": cls.DEFAULT_EMBEDDING_MODEL,
                "default_llm": cls.DEFAULT_LLM_MODEL,
                "temperature": cls.DEFAULT_TEMPERATURE,
                "max_tokens": cls.DEFAULT_MAX_TOKENS
            },
            "storage": {
                "vector_store": cls.VECTOR_STORE_PATH,
                "data_dir": cls.DATA_DIR,
                "temp_dir": cls.TEMP_DIR
            },
            "files": {
                "max_size_mb": cls.MAX_FILE_SIZE / 1024 / 1024,
                "supported_extensions": cls.SUPPORTED_EXTENSIONS
            },
            "processing": {
                "chunk_size": cls.DEFAULT_CHUNK_SIZE,
                "chunk_overlap": cls.DEFAULT_CHUNK_OVERLAP,
                "search_k": cls.DEFAULT_SEARCH_K,
                "batch_size": cls.BATCH_SIZE
            }
        }


# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠ import
Config.create_directories()


# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
if __name__ == "__main__":
    print("üîß ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö Thai RAG Chatbot")
    print("=" * 50)
    
    config_summary = Config.get_config_summary()
    
    for section, settings in config_summary.items():
        print(f"\nüìã {section.upper()}:")
        for key, value in settings.items():
            print(f"  {key}: {value}")
    
    print(f"\nüìÅ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á:")
    print(f"  - {Config.VECTOR_STORE_PATH}")
    print(f"  - {Config.DATA_DIR}")
    print(f"  - {Config.TEMP_DIR}")
    
    print(f"\nü§ñ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö:")
    
    print("  Embedding Models:")
    for name, model in Config.get_embedding_models().items():
        print(f"    - {name}: {model}")
    
    print("  LLM Models:")
    for name, model in Config.get_llm_models().items():
        print(f"    - {name}: {model}")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå
    print(f"\n‚úÖ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå:")
    test_files = [
        ("test.txt", 1000),
        ("test.pdf", 100000000),  # ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
        ("test.xyz", 1000)        # ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
    ]
    
    for file_path, file_size in test_files:
        is_valid, message = Config.validate_file(file_path, file_size)
        status = "‚úÖ" if is_valid else "‚ùå"
        print(f"  {status} {file_path}: {message}")